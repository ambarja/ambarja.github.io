{
  "hash": "202896d4d15b0aac01e477e935416b3a",
  "result": {
    "markdown": "---\ntitle: \"TidyModels - SVM & Random Forests\"\ndescription: |\n  Learning Tidymodels package using the Chocolates dataset from TidyTuesday.\nauthor:\n  - name: Karat Sidhu\n    url: {}\ndate: 2022-05-22\nimage: images/logo.png\ncategories:\n  - TidyModels\n  - Random Forest\n  - SVM\n  - Machine Learning\n  - Text-analysis\ntoc: true\ntoc-title: Table of contents\ntoc-location: left\n---\n\n\n\n\n# TidyModels Text Prediction using Random Forests and SVM\n\nThe purpose of this post is for me to learn more about tidymodels package, as well as learning and deploying models for prediction.\nThis is hopefully a first in the series of many posts where I try and learn more about various algorithms that are present in this package.\n\n# Chocolate Ratings\n\nThe dataset used today will be from the TidyTuesday data[^1].\nSince I am almost a complete beginner I will be making use of Julie Silge's great blogs[^2] to learn more about how to use and run the models\n.\n\n[^1]: <https://github.com/rfordatascience/tidytuesday/blob/master/data/2022/2022-01-18/readme.md>\n\n[^2]: <https://juliasilge.com/blog/>\n\n## Goal\n\nThe goal of this first exercise is to learn more about text analysis and using various reviews from chocolates to predict the ratings for a particular chocolate bar.\n\nThis is a very vague and non specific way of predicting the outcome but a good starting point in learning how the algorithms work.\n## Loading the packages\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n```\n\n::: {.cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n```\n:::\n\n::: {.cell-output-stderr}\n```\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n```\n:::\n\n::: {.cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nlibrary(tidytext)\nlibrary(tidymodels)\n```\n\n::: {.cell-output-stderr}\n```\n── Attaching packages ────────────────────────────────────── tidymodels 0.2.0 ──\n```\n:::\n\n::: {.cell-output-stderr}\n```\n✔ broom        0.8.0     ✔ rsample      0.1.1\n✔ dials        0.1.1     ✔ tune         0.2.0\n✔ infer        1.0.0     ✔ workflows    0.2.6\n✔ modeldata    0.1.1     ✔ workflowsets 0.2.1\n✔ parsnip      0.2.1     ✔ yardstick    0.0.9\n✔ recipes      0.2.0     \n```\n:::\n\n::: {.cell-output-stderr}\n```\n── Conflicts ───────────────────────────────────────── tidymodels_conflicts() ──\n✖ scales::discard() masks purrr::discard()\n✖ dplyr::filter()   masks stats::filter()\n✖ recipes::fixed()  masks stringr::fixed()\n✖ dplyr::lag()      masks stats::lag()\n✖ yardstick::spec() masks readr::spec()\n✖ recipes::step()   masks stats::step()\n• Search for functions across packages at https://www.tidymodels.org/find/\n```\n:::\n\n```{.r .cell-code}\nlibrary(textrecipes)\n```\n:::\n\n## Loading the data\n\n::: {.cell}\n\n```{.r .cell-code}\nchocolate <- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2022/2022-01-18/chocolate.csv')\n```\n\n::: {.cell-output-stderr}\n```\nRows: 2530 Columns: 10\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (7): company_manufacturer, company_location, country_of_bean_origin, spe...\ndbl (3): ref, review_date, rating\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n```\n:::\n:::\n\n# Exploratory Data Analysis\n\n## Lets see how the ratings are distributed\n\n::: {.cell}\n\n```{.r .cell-code}\nchocolate |> \n  ggplot(aes(rating)) +\n  geom_histogram(bins = 12) +\n  theme_minimal() +\n  hrbrthemes::theme_ipsum()\n```\n\n::: {.cell-output-display}\n![](tidymodels-svm-random-forests_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\nFrom the chart above, it looks like that most chocolates are rated somewhere in the range of 2.5 and 3.75 with a few high-rated and low-rated exceptions.\n\nSo we'll be comparing the ratings and the descriptive words used to describe the corresponding ratings.\n\n## TidyText words analysis\n\nLets use the tidytext() library to check what are some of the most common words used to describe the flavor of each chocolate in the data-set.\n\n::: {.cell}\n\n```{.r .cell-code}\n# split the characteristics column into words using tidytext, and make a new column called word instead of the original.\n\ntidy_chocolate <-\n  chocolate %>%\n  unnest_tokens(word, most_memorable_characteristics)\n\ntidy_chocolate |> \n  group_by(word) |> \n  summarise(total = n()) |> arrange(desc(total))\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 547 × 2\n   word    total\n   <chr>   <int>\n 1 cocoa     419\n 2 sweet     318\n 3 nutty     278\n 4 fruit     273\n 5 roasty    228\n 6 mild      226\n 7 sour      208\n 8 earthy    199\n 9 creamy    189\n10 intense   178\n# … with 537 more rows\n```\n:::\n:::\n\nIt looks like the usual expected words like cocoa, sweet, nutty etc are the most prevalent.\n\nSince we know what the most common words are, its time to look at how an average chocolate described by these words is rated.\n\n### Rating vs Word relationship\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy_chocolate |> \n  group_by(word) |> \n  summarise(\n    n = n(),\n    rating = mean(rating) \n  ) |> \n  ggplot(aes(n, rating)) +\n  geom_jitter(color = \"maroon\", alpha = 0.7) +\n   geom_hline(\n    yintercept = mean(chocolate$rating), lty = 2,\n    color = \"gray50\", size = 1.5\n  ) + ggrepel::geom_text_repel(aes(label = word), max.overlaps = 15) +\n  scale_x_log10() +\n  theme_minimal() +\n  hrbrthemes::theme_ipsum()\n```\n\n::: {.cell-output-stderr}\n```\nWarning: ggrepel: 495 unlabeled data points (too many overlaps). Consider\nincreasing max.overlaps\n```\n:::\n\n::: {.cell-output-display}\n![](tidymodels-svm-random-forests_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\nWords like chemical, burnt, medicinal, pastey, bitter etc look to be associated with generally low rated chocolate, while cocoa, complex, creamy, balanced etc are higher rated chocolates.[^3]\n\n[^3]: General trend observed, and in no ways indicative of the true rating of each chocolate.\n\nWe now have a bit of an idea of what the general feeling of the data rating, and we can go on to buiding the models.\n\n# Model Building\n\n## Building Models with Tidymodels\n\nLet's start our modeling by setting up our \"data budget.\" We'll stratify by our outcome \"rating\" which is what we want to measure using the tokens.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels)\n```\n:::\n\nTime to split the data into training and testing data\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nchoco_split <- initial_split(chocolate, strata = rating)\nchoco_train <- training(choco_split)\nchoco_test <- testing(choco_split)\n```\n:::\n\n-   create resampling folds from the *training* set\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(234)\nchoco_folds <- vfold_cv(choco_train, strata = rating)\nchoco_folds\n```\n\n::: {.cell-output-stdout}\n```\n#  10-fold cross-validation using stratification \n# A tibble: 10 × 2\n   splits             id    \n   <list>             <chr> \n 1 <split [1705/191]> Fold01\n 2 <split [1705/191]> Fold02\n 3 <split [1705/191]> Fold03\n 4 <split [1706/190]> Fold04\n 5 <split [1706/190]> Fold05\n 6 <split [1706/190]> Fold06\n 7 <split [1707/189]> Fold07\n 8 <split [1707/189]> Fold08\n 9 <split [1708/188]> Fold09\n10 <split [1709/187]> Fold10\n```\n:::\n:::\n\nWe're done with splitting the data into test and train, and we're using the training data to train the model.\nSo the first step will involve setting up feature engineering.\nThe data right now is complex and we need to transform it into features that are useful for our model tokenization and computing.\n\n## Tokenization\n\n(if that's a word?)\n\nWe'll use `textrecipes` package to tokenize \"most_memorable_characteristics\" wrt \"ratings\" and look at the 100 most common words used (here they are called tokens).All of this is done on the\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(textrecipes)\n\nchoco_rec <-\n  recipe(rating ~ most_memorable_characteristics, data = choco_train) %>%\n  step_tokenize(most_memorable_characteristics) %>%\n  step_tokenfilter(most_memorable_characteristics, max_tokens = 100) %>% # 100 most common words\n  step_tfidf(most_memorable_characteristics) # step frequeence df\n\n\n# looking at the tokenized data\nprep(choco_rec) %>% bake(new_data = NULL)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1,896 × 101\n   rating tfidf_most_memorab… tfidf_most_memo… tfidf_most_memo… tfidf_most_memo…\n    <dbl>               <dbl>            <dbl>            <dbl>            <dbl>\n 1   3                   0                   0                0                0\n 2   2.75                0                   0                0                0\n 3   3                   0                   0                0                0\n 4   3                   0                   0                0                0\n 5   2.75                0                   0                0                0\n 6   3                   1.38                0                0                0\n 7   2.75                0                   0                0                0\n 8   2.5                 0                   0                0                0\n 9   2.75                0                   0                0                0\n10   3                   0                   0                0                0\n# … with 1,886 more rows, and 96 more variables:\n#   tfidf_most_memorable_characteristics_base <dbl>,\n#   tfidf_most_memorable_characteristics_basic <dbl>,\n#   tfidf_most_memorable_characteristics_berry <dbl>,\n#   tfidf_most_memorable_characteristics_bitter <dbl>,\n#   tfidf_most_memorable_characteristics_black <dbl>,\n#   tfidf_most_memorable_characteristics_bland <dbl>, …\n```\n:::\n:::\n\nThe result is basically a new dataframe from the \"choco_train\" data with all the ratings, and the frequency of corresponding 100 most common words.\n\n## Model Specification\n\nThe models being used to evaluate the data are random forest, and support vector machine (SVM).\n\nRandom Forest Model is usually not great for text based or language data[^4] and SVM normally a good model to use for such data, so we'll be trying both.\n\n[^4]: Random forest in remote sensing: A review of applications and future directions by Mariana Belgiu\n\n### Random Forest Model\n\n#### Specifying the RF model\n\nComputational engine: ranger (default)\n\n::: {.cell}\n\n```{.r .cell-code}\n### Computational engine: ranger\n\nrf_spec <-\n  rand_forest(trees = 500) %>%\n  set_mode(\"regression\")\n\nrf_spec\n```\n\n::: {.cell-output-stdout}\n```\nRandom Forest Model Specification (regression)\n\nMain Arguments:\n  trees = 500\n\nComputational engine: ranger \n```\n:::\n:::\n\n### SVM Model\n\n#### Model Specification\n\nComputational engine: LiblineaR (default)\n\n::: {.cell}\n\n```{.r .cell-code}\nsvm_spec <-\n  svm_linear() %>%\n  set_mode(\"regression\")\n\nsvm_spec\n```\n\n::: {.cell-output-stdout}\n```\nLinear Support Vector Machine Specification (regression)\n\nComputational engine: LiblineaR \n```\n:::\n:::\n\nThe models have been specified and now we can run each of them in our workflow().\n\nNote: The SVM requires the predictors to all be on the same scale[^5], but all our predictors are now tf-idf values so we should be pretty much fine.\n\n[^5]: <https://www.tmwr.org/pre-proc-table.html>\n\n::: {.cell}\n\n```{.r .cell-code}\nsvm_wf <- workflow(choco_rec, svm_spec)\nrf_wf <- workflow(choco_rec, rf_spec)\n```\n:::\n\nWe are done with making the models and now can evaluate both of them.\n\n# Model Evaluation\n\nThese workflows have no tuning parameters so we can evaluate them as they are.\n(Random forest models can be tuned but they tend to work fine with the defaults as long as you have enough trees.)\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel() # run them in parallel\n\ncontrl_preds <- control_resamples(save_pred = TRUE)\n\nsvm_rs <- fit_resamples(\n  svm_wf,\n  resamples = choco_folds,\n  control = contrl_preds\n)\n\nranger_rs <- fit_resamples(\n  rf_wf,\n  resamples = choco_folds,\n  control = contrl_preds\n)\n```\n:::\n\n## How did these two models compare?\n\n### SVM\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(svm_rs)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.347    10 0.00656 Preprocessor1_Model1\n2 rsq     standard   0.367    10 0.0181  Preprocessor1_Model1\n```\n:::\n:::\n\n### Random Forest\n\n::: {.cell}\n\n```{.r .cell-code}\ncollect_metrics(ranger_rs)\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.350    10 0.00688 Preprocessor1_Model1\n2 rsq     standard   0.359    10 0.0164  Preprocessor1_Model1\n```\n:::\n:::\n\nWe can visualize these results by comparing the predicted rating with the true rating:\n\n::: {.cell}\n\n```{.r .cell-code}\nbind_rows(\n  collect_predictions(svm_rs) %>%\n    mutate(mod = \"SVM\"),\n  collect_predictions(ranger_rs) %>%\n    mutate(mod = \"ranger\")\n) %>%\n  ggplot(aes(rating, .pred, color = id)) +\n  geom_abline(lty = 2, color = \"gray50\", size = 1.2) +\n  geom_jitter(width = 0.4, alpha = 0.4) +\n  facet_wrap(vars(mod)) +\n  coord_fixed() + hrbrthemes::theme_ipsum()\n```\n\n::: {.cell-output-display}\n![](tidymodels-svm-random-forests_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n## Choosing a model\n\nNeither of these prediction models look great, judging by their rsq values and the general prediction.\nHowever, we can probably use the SVM model for further analysis since it doesn't take as long as the RF model.\nThe function last_fit() fits one final time on the training data and evaluates on the testing data.\n\n**This is the first time we have used the testing data.**\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_fitted <- last_fit(svm_wf, choco_split)\ncollect_metrics(final_fitted) ## metrics evaluated on the *testing* data\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 2 × 4\n  .metric .estimator .estimate .config             \n  <chr>   <chr>          <dbl> <chr>               \n1 rmse    standard       0.381 Preprocessor1_Model1\n2 rsq     standard       0.348 Preprocessor1_Model1\n```\n:::\n:::\n\nAgain the results don't look particularly great, but its just a practise run.\n\nNow the \"final_fitted\" object can be used to predict the ratings for everything in the testing data.\n\nThis is done by using the workflow to predict the choco_test data.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinal_wf <- extract_workflow(final_fitted)\npredict(final_wf, choco_test[55, ])\n```\n\n::: {.cell-output-stdout}\n```\n# A tibble: 1 × 1\n  .pred\n  <dbl>\n1  3.51\n```\n:::\n:::\n\nNote: You can save this fitted final_wf object to use later with new data, for example with readr::write_rds().\n\n## Rating Bais Visualization\n\nWe can now directly visualize the baises for each of the 'token' or term and how they affect the rating of a particular chocolate. This is done from the final_fitted object\n\n\n::: {.cell}\n\n```{.r .cell-code}\nextract_workflow(final_fitted) %>%\n  tidy() %>% # make a table\n  filter(term != \"Bias\") %>% # remove biases\n  group_by(estimate > 0) %>%\n  slice_max(abs(estimate), n = 10) %>% \n  ungroup() %>%\n  mutate(term = str_remove(term, \"tfidf_most_memorable_characteristics_\")) %>%\n  ggplot(aes(estimate, fct_reorder(term, estimate), fill = estimate > 0)) +\n  geom_col(alpha = 0.8) +\n  scale_fill_discrete(labels = c(\"low ratings\", \"high ratings\")) +\n  labs(y = NULL, fill = \"More from...\") +\n  hrbrthemes::theme_ipsum()\n```\n\n::: {.cell-output-display}\n![](tidymodels-svm-random-forests_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\nWe see what we noticed during our EDA, i.e. the words like off, bitter, chemical heavily turn the rating negative/low while words like creamy, cocoa, complex etc. tend to be associated with higher rated chocolates.\n",
    "supporting": [
      "tidymodels-svm-random-forests_files/figure-html"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}