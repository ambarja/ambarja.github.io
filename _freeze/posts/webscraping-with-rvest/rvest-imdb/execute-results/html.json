{
  "hash": "bfea53a4f83b053e348f2b4e13ceedf3",
  "result": {
    "markdown": "---\ntitle: \"Web scraping with R and RVest\"\ndescription: |\n  Step by step guide to scraping IMDB for TV Series ratings and votes using R and `rvest` package\nauthor:\n  - name: Karat Sidhu\n    url: {}\ndate: 2022-06-20\ncategories:\n  - Data-Analysis\n  - Tidyverse\n  - misc\n  - Long-Read\nimage: images/logo.jpeg\ntoc: true\ntoc-title: Table of contents\ntoc-location: left\n---\n\n\n![](images/logo.jpeg){fig-width=\"300px\"}\n[Image from Reddit.com by u/booooooop123]{.aside}\n\n\n# Introduction\n\nThere are a few tutorials available for scraping IMDB for TV Series ratings and votes using Python but I wanted to write my own tutorial to learn how to scrape IMDB for TV Series ratings and votes using R and `rvest` package because of the lack of such tutorials in R. Even when such guides are available, they are not very clear and usually deal with scraping data from IMDB data related to top 100/top 1000 lists and not specific seasons of a particular TV Series. \n\nThe series I am going to scrape is [South Park](https://www.imdb.com/title/tt0121955/). This is a TV Series that is popular in the US and is one of the most popular TV Shows in the world. Moreover, this show has over 25 seasons and a lot of episodes, so it helps with the learning of scraping data when dealing with a relatively long dataset compared to a top 100 list. \n\n\nThe basic steps to scrape data are:\n\n- Step 1: Find the URL of the page that contains the data you want to scrape\n\n- Step 2: Parse the data\n\n- Step 3: Repeat the steps above for each page you want to scrape\n\n- Step 4: Transform the data\n\n- Step 5: Check the data, clean it\n\n- Step 6: Save the data\n\n# Prerequisites\n\nWe need to have a working R installation on your computer. In addition, you will need to have the `rvest` package installed. You can install it by running the following command in your R console:\n\n`install.packages(\"rvest\")`\n\n`rvest` package helps us to scrape data from the web. \n\n:::{.callout-note}\n## RVest Note\n\nRVest is part of the tidyverse. To find out more about it visit [rvest documentation](https://rvest.tidyverse.org/).\n\n:::\n\nAdditionally, it is recommended you install the [CSS Selector Gadget](https://chrome.google.com/webstore/detail/selectorgadget/mhjhnkcfbdhnjickkkdbjoemdmbfginb?hl=en) for your web browser. It is a Chrome extension that helps you to select elements on the web page and makes it much simpler to find the elements you want to scrape. It is not a necessary dependency for this tutorial, but it is recommended, alternatively using the \"Inspect Element\" option in your browser would work as well.\n\n`Lubridate` package is useful when working with dates. Since we will be extract the airdate of each episode, `Lubridate` is helpful in converting it to a usable format.\n\nI will be using the following packages for this tutorial:\n\n- `stringr`\n\n- `readr`\n\n- `magrittr`\n\nTo make it simpler, install the entire `tidyverse` set of packages, because they are useful for analysis and visualization of the data scraped.\n\n# Scraping\n\nWe will be extracting the text elements from the IMDB pages that contain the data we want to scrape. Once extracted, those elements are saved as lists that become the columns of a data frame. Assembling the data frame is the last step of the scraping process.\n\n\n## Find & navigate to the URL\n\nTo find the exact url of the page that we want to extract the data from, we first look at the [South Park Homepage on IMDB](https://www.imdb.com/title/tt0121955/). This page contains the rating and vote count of the South Park TV Series, but it does not contain the ratings and votes of the seasons of the TV Series for each individual episode/season.\n\nOn the top of the page, we see the list of episodes of South Park, and [clicking that link](https://www.imdb.com/title/tt0121955/episodes) takes me to the latest season of South Park, which is 25 at the time of writing this post.\n\nFor simplicity, we will start with the first season, which is under the link [Season 1](https://www.imdb.com/title/tt0121955/episodes?season=1).\n\n\n## Parse the URL\n\nUsing the `read_html` function, we can parse the HTML code of the page\n\n```default\n\nlink <- \"https://www.imdb.com/title/tt0121955/episodes?season=1\"\npage <- read_html(link)\n\n\n```\n\nThis page should now appear in the R console environment. We can see that the page contains a list of HTML elements. It can take a minute to get the page, depending on your internet connection/processor speed.\n\n## Extract each element\n\nUsing the CSS Selector Gadget, we can find the elements we want to scrape. The following code snippet will find the elements that contain the TV Series name, the TV Series rating, the TV Series votes and the TV Series year and then it will extract the text from each of them. \n\n### Episode Name\n\n```default\n    episode_name <- page |>\n        html_nodes(\"#episodes_content strong a\") |>\n        html_text()\n```\n\n### Episode Number\n\n```default\n    episode_season <- page |>\n        html_nodes(\".zero-z-index div\") |>\n        html_text()\n\n```\n### Episode Rating\n\n```default\nrating <- page |>\n  html_nodes(\".ipl-rating-star.small .ipl-rating-star__rating\") |>\n        html_text()\n```\n### Episode Votes\n\n```default\n    total_votes <- page |>\n        html_nodes(\".ipl-rating-star__total-votes\") |>\n        html_text()\n\n```\n\n### Air Date\n\n```default\n\n    air_date <- page |>\n        html_nodes(\".airdate\") |>\n        html_text()\n\n```\n\n\n### Episode Description\n\n```default\n    description <- page |>\n        html_nodes(\".item_description\") |>\n        html_text()\n\n```\n\n### Repeat for each season\n\nThe codes above will scrape the data for one season. To scrape the data for all seasons, we need to repeat the above steps for each season. To do that, we need to use the `for` loop. Additionally, we need to change the `url` variable to point to the correct URL for each season.\n\n## Final Code\n\nThe final code snippet will look like the following:\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(rvest)\nlibrary(tidyverse)\n```\n\n::: {.cell-output-stderr}\n```\n── Attaching packages ─────────────────────────────────────── tidyverse 1.3.1 ──\n```\n:::\n\n::: {.cell-output-stderr}\n```\n✔ ggplot2 3.3.6     ✔ purrr   0.3.4\n✔ tibble  3.1.7     ✔ dplyr   1.0.9\n✔ tidyr   1.2.0     ✔ stringr 1.4.0\n✔ readr   2.1.2     ✔ forcats 0.5.1\n```\n:::\n\n::: {.cell-output-stderr}\n```\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter()         masks stats::filter()\n✖ readr::guess_encoding() masks rvest::guess_encoding()\n✖ dplyr::lag()            masks stats::lag()\n```\n:::\n\n```{.r .cell-code}\nsouth_park <- data.frame()\n\nfor (seasons in seq(from = 1, to = 25, by = 1)) {\n    link <- paste0(\"https://www.imdb.com/title/tt0121955/episodes?season=\", seasons)\n\n    page <- read_html(link)\n\n    episode_name <- page |>\n        html_nodes(\"#episodes_content strong a\") |>\n        html_text()\n\n    rating <- page |>\n        html_nodes(\".ipl-rating-star.small .ipl-rating-star__rating\") |>\n        html_text()\n\n    total_votes <- page |>\n        html_nodes(\".ipl-rating-star__total-votes\") |>\n        html_text()\n\n    air_date <- page |>\n        html_nodes(\".airdate\") |>\n        html_text()\n\n    description <- page |>\n        html_nodes(\".item_description\") |>\n        html_text()\n\n    episode_season <- page |>\n        html_nodes(\".zero-z-index div\") |>\n        html_text()\n\n    south_park <- rbind(south_park, data.frame(episode_name, episode_season,\n        rating,\n        total_votes,\n        air_date,\n        description,\n        stringsAsFactors = FALSE\n    ))\n}\n```\n:::\n\n\n\n## Make the Dataframe\n\nThe final code snippet will create a data frame with the following columns:\n\n- `episode_name`\n\n- `episode_season`\n\n- `rating`\n\n- `total_votes`\n\n- `air_date`\n\n- `description`\n\n\nand save it under the variable `south_park`.\n\nLet use look at the data frame.\n\n::: {.cell}\n\n```{.r .cell-code}\nsouth_park  |> head(10)  |> gt::gt()  |> gtExtras::gt_theme_538()\n```\n\n::: {.cell-output-display}\n```{=html}\n<div id=\"dgtdwmrpuy\" style=\"overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>@import url(\"https://fonts.googleapis.com/css2?family=Chivo:ital,wght@0,100;0,200;0,300;0,400;0,500;0,600;0,700;0,800;0,900;1,100;1,200;1,300;1,400;1,500;1,600;1,700;1,800;1,900&display=swap\");\nhtml {\n  font-family: Chivo, -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, 'Helvetica Neue', 'Fira Sans', 'Droid Sans', Arial, sans-serif;\n}\n\n#dgtdwmrpuy .gt_table {\n  display: table;\n  border-collapse: collapse;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: 300;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: none;\n  border-top-width: 3px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_heading {\n  background-color: #FFFFFF;\n  text-align: left;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#dgtdwmrpuy .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 0;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#dgtdwmrpuy .gt_bottom_border {\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_col_headings {\n  border-top-style: none;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #000000;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 80%;\n  font-weight: normal;\n  text-transform: uppercase;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#dgtdwmrpuy .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 80%;\n  font-weight: normal;\n  text-transform: uppercase;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#dgtdwmrpuy .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#dgtdwmrpuy .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#dgtdwmrpuy .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #000000;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#dgtdwmrpuy .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 80%;\n  font-weight: bolder;\n  text-transform: uppercase;\n  border-top-style: none;\n  border-top-width: 2px;\n  border-top-color: #000000;\n  border-bottom-style: solid;\n  border-bottom-width: 1px;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#dgtdwmrpuy .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 80%;\n  font-weight: bolder;\n  border-top-style: none;\n  border-top-width: 2px;\n  border-top-color: #000000;\n  border-bottom-style: solid;\n  border-bottom-width: 1px;\n  border-bottom-color: #FFFFFF;\n  vertical-align: middle;\n}\n\n#dgtdwmrpuy .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#dgtdwmrpuy .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#dgtdwmrpuy .gt_row {\n  padding-top: 3px;\n  padding-bottom: 3px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#dgtdwmrpuy .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 80%;\n  font-weight: bolder;\n  text-transform: uppercase;\n  border-right-style: solid;\n  border-right-width: 0px;\n  border-right-color: #FFFFFF;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dgtdwmrpuy .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#dgtdwmrpuy .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#dgtdwmrpuy .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dgtdwmrpuy .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#dgtdwmrpuy .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dgtdwmrpuy .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#dgtdwmrpuy .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-left: 4px;\n  padding-right: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dgtdwmrpuy .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#dgtdwmrpuy .gt_sourcenote {\n  font-size: 12px;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#dgtdwmrpuy .gt_left {\n  text-align: left;\n}\n\n#dgtdwmrpuy .gt_center {\n  text-align: center;\n}\n\n#dgtdwmrpuy .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#dgtdwmrpuy .gt_font_normal {\n  font-weight: normal;\n}\n\n#dgtdwmrpuy .gt_font_bold {\n  font-weight: bold;\n}\n\n#dgtdwmrpuy .gt_font_italic {\n  font-style: italic;\n}\n\n#dgtdwmrpuy .gt_super {\n  font-size: 65%;\n}\n\n#dgtdwmrpuy .gt_two_val_uncert {\n  display: inline-block;\n  line-height: 1em;\n  text-align: right;\n  font-size: 60%;\n  vertical-align: -0.25em;\n  margin-left: 0.1em;\n}\n\n#dgtdwmrpuy .gt_footnote_marks {\n  font-style: italic;\n  font-weight: normal;\n  font-size: 75%;\n  vertical-align: 0.4em;\n}\n\n#dgtdwmrpuy .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#dgtdwmrpuy .gt_slash_mark {\n  font-size: 0.7em;\n  line-height: 0.7em;\n  vertical-align: 0.15em;\n}\n\n#dgtdwmrpuy .gt_fraction_numerator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: 0.45em;\n}\n\n#dgtdwmrpuy .gt_fraction_denominator {\n  font-size: 0.6em;\n  line-height: 0.6em;\n  vertical-align: -0.05em;\n}\n\ntbody tr:last-child {\n  border-bottom: 2px solid #ffffff00;\n}\n</style>\n<table class=\"gt_table\">\n  \n  <thead class=\"gt_col_headings\">\n    <tr>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">episode_name</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">episode_season</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">rating</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">total_votes</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">air_date</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" style=\"border-top-width: 0px; border-top-style: solid; border-top-color: black;\">description</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td class=\"gt_row gt_left\">Unaired Pilot</td>\n<td class=\"gt_row gt_left\">S1, Ep0</td>\n<td class=\"gt_row gt_left\">7.6</td>\n<td class=\"gt_row gt_left\">(816)</td>\n<td class=\"gt_row gt_left\">\n            26 Sep. 2019\n    </td>\n<td class=\"gt_row gt_left\">\nCartman wakes up and realizes he was abducted by aliens after hearing it from his friends. He is in major denial at first though, but even Chef is a believer.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Cartman Gets an Anal Probe</td>\n<td class=\"gt_row gt_left\">S1, Ep1</td>\n<td class=\"gt_row gt_left\">7.9</td>\n<td class=\"gt_row gt_left\">(4,459)</td>\n<td class=\"gt_row gt_left\">\n            13 Aug. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nCartman's dream about being abducted by aliens turns out to have actually happened, and when the aliens take Kyle's brother, all of them must find a way to bring the aliens back and confront them.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Weight Gain 4000</td>\n<td class=\"gt_row gt_left\">S1, Ep2</td>\n<td class=\"gt_row gt_left\">7.6</td>\n<td class=\"gt_row gt_left\">(3,518)</td>\n<td class=\"gt_row gt_left\">\n            27 Aug. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nKathie Lee Gifford comes to South Park to present an award to Cartman, and Mr. Garrison hopes to use the event to assassinate her.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Volcano</td>\n<td class=\"gt_row gt_left\">S1, Ep3</td>\n<td class=\"gt_row gt_left\">7.7</td>\n<td class=\"gt_row gt_left\">(3,398)</td>\n<td class=\"gt_row gt_left\">\n            20 Aug. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nThe kids go hunting with the rather trigger happy Jimbo and Ned. Little do they know that a volcano is on the verge of erupting.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Big Gay Al's Big Gay Boat Ride</td>\n<td class=\"gt_row gt_left\">S1, Ep4</td>\n<td class=\"gt_row gt_left\">7.6</td>\n<td class=\"gt_row gt_left\">(3,286)</td>\n<td class=\"gt_row gt_left\">\n            3 Sep. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nStan becomes distracted from the upcoming football game because his dog is gay, so he turns to the gayest man in town for advice, Big Gay Al.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">An Elephant Makes Love to a Pig</td>\n<td class=\"gt_row gt_left\">S1, Ep5</td>\n<td class=\"gt_row gt_left\">7.5</td>\n<td class=\"gt_row gt_left\">(3,049)</td>\n<td class=\"gt_row gt_left\">\n            10 Sep. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nKyle tries to crossbreed an elephant with a pig to win a science contest.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Death</td>\n<td class=\"gt_row gt_left\">S1, Ep6</td>\n<td class=\"gt_row gt_left\">8.0</td>\n<td class=\"gt_row gt_left\">(3,128)</td>\n<td class=\"gt_row gt_left\">\n            17 Sep. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nGrampa wants Stan to kill him, the parents all want to kill the Terrance and Philip show, and Death just wants to kill someone.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Pinkeye</td>\n<td class=\"gt_row gt_left\">S1, Ep7</td>\n<td class=\"gt_row gt_left\">8.3</td>\n<td class=\"gt_row gt_left\">(3,262)</td>\n<td class=\"gt_row gt_left\">\n            29 Oct. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nThe living dead beset South Park after a bottle of Worcestershire sauce mixes with embalming fluid at the mortuary; Tina Yothers judged a costume contest.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Starvin' Marvin</td>\n<td class=\"gt_row gt_left\">S1, Ep8</td>\n<td class=\"gt_row gt_left\">8.1</td>\n<td class=\"gt_row gt_left\">(3,141)</td>\n<td class=\"gt_row gt_left\">\n            19 Nov. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nThe boys sponsor a starving Ethiopian child, only to have him show up on their doorstep.    </td></tr>\n    <tr><td class=\"gt_row gt_left\">Mr. Hankey, the Christmas Poo</td>\n<td class=\"gt_row gt_left\">S1, Ep9</td>\n<td class=\"gt_row gt_left\">8.1</td>\n<td class=\"gt_row gt_left\">(3,152)</td>\n<td class=\"gt_row gt_left\">\n            17 Dec. 1997\n    </td>\n<td class=\"gt_row gt_left\">\nThe town is forced to remove anything that either has anything to do with Christmas or is offensive in the least bit to anyone. And Kyle tries to convince everyone of the existence of \"Mr. Hankey, the Christmas Poo.\"    </td></tr>\n  </tbody>\n  \n  \n</table>\n</div>\n```\n:::\n:::\n\nThe scraped data is now in the `south_park` data frame, and can be saved from here. However, to further analyze the data, it needs to be cleaned up.\n\n\n# Data Cleaning\n\nThe data frame we created above contains the data we want to analyze. However, the data is not in the most usable format. We need to clean the data to make it more useful.\n\n\n\n## Total Votes to Integer\n\nRemove the () from the total votes string, and convert it into an integer type.\n\n```default\nsouth_park$total_votes <- south_park$total_votes |>\n    str_replace_all(\"\\\\(|\\\\)|\\\\,\", \"\") |>\n    as.integer()\n```\n\n## Rating to a double\n\n```default\nsouth_park$rating <- as.double(south_park$rating)\n\n```\n\n## Air_date to a Date\n\n```default\nsouth_park$air_date <-\n    str_replace_all(south_park$air_date, \"\\\\n\", \"\") |>\n    trimws() |>\n    lubridate::dmy()\n```\n\n## Description column cleaning\nThe description column contains a new line, so need to remove it.\n\n```default\nsouth_park$description <-\n    str_replace_all(south_park$description, \"\\\\n\", \"\")\n```\n\n## Save the data\n\nFinally save the data as a new dataframe:\n\n```default\nclean_sp <- south_park |>\n    mutate(\n        season = str_extract(episode_season, \"(?<=S)[:digit:]+\"),\n        episode = str_extract(episode_season, \"[:digit:]+$\")\n    ) |>\n    relocate(season, .before = rating) |>\n    relocate(episode, .before = rating) |>\n    select(-episode_season) |>\n    mutate(\n        id = row_number()\n    )\n```\n\n# Conclusion\n\nFor static webpages, Rvest package is a great tool to scrape data from a webpage. It is easy to use, and it is very flexible. Further, the data is in a very usable format, and does not need to be cleaned up a great deal. Each function in the package is well documented, and the code is easy to read, like most tidyverse packages.\n\n# References\n\n- [Rvest](https://rvest.tidyverse.org/)\n\n:::{.callout-caution collapse=\"true\"}\n## Session Info\n\nR version 4.2.0 (2022-04-22)\nPlatform: aarch64-apple-darwin20 (64-bit)\nRunning under: macOS Monterey 12.4\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2-arm64/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] forcats_0.5.1   stringr_1.4.0   dplyr_1.0.9     purrr_0.3.4    \n [5] readr_2.1.2     tidyr_1.2.0     tibble_3.1.7    ggplot2_3.3.6  \n [9] tidyverse_1.3.1 rvest_1.0.2    \n\nloaded via a namespace (and not attached):\n [1] tidyselect_1.1.2  rematch2_2.1.2    haven_2.5.0       paletteer_1.4.0  \n [5] colorspace_2.0-3  vctrs_0.4.1       generics_0.1.2    htmltools_0.5.2  \n [9] utf8_1.2.2        rlang_1.0.2       pillar_1.7.0      glue_1.6.2       \n[13] withr_2.5.0       DBI_1.1.2         gtExtras_0.3.1    selectr_0.4-2    \n[17] dbplyr_2.1.1      modelr_0.1.8      readxl_1.4.0      lifecycle_1.0.1  \n[21] munsell_0.5.0     gtable_0.3.0      cellranger_1.1.0  fontawesome_0.2.2\n[25] tzdb_0.3.0        fastmap_1.1.0     curl_4.3.2        fansi_1.0.3      \n[29] broom_0.8.0       checkmate_2.1.0   scales_1.2.0      backports_1.4.1  \n[33] jsonlite_1.8.0    fs_1.5.2          hms_1.1.1         digest_0.6.29    \n[37] stringi_1.7.6     grid_4.2.0        cli_3.3.0         tools_4.2.0      \n[41] sass_0.4.1        magrittr_2.0.3    crayon_1.5.1      pkgconfig_2.0.3  \n[45] ellipsis_0.3.2    xml2_1.3.3        reprex_2.0.1      lubridate_1.8.0  \n[49] assertthat_0.2.1  gt_0.6.0          httr_1.4.3        rstudioapi_0.13  \n[53] R6_2.5.1          compiler_4.2.0   \n\n:::\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": [],
    "engineDependencies": {},
    "preserve": {},
    "postProcess": null
  }
}